---
title: Task 4
category: Tasks
order: 4
brief: 
---

{::comment}
To be announced.
{:/comment}

## Introduction

The goal of this task is to introduce reactive control.
The reactive control of the youBot robot is realized by using data acquired from the LIDAR sensor to avoid obstacles in a specified task (moving along the walls).
In this tutorial the 'reactive control' refers to the control of the speed of the robot without any trajectory planning.

You should write a program that enables youBot to move along walls, as presented in the figure below.
The robot should use laser scanners in order to detect the wall, move along it (i.e. keep the distance) and avoid collisions.

![Task 3]({{ site.baseurl }}/images/tut_02_path.jpg){:width="75%"}

The video below shows an example motion generated by the controller you need to implement:
<iframe width="560" height="315" src="https://www.youtube.com/embed/BgH8s60vglg" frameborder="0" allowfullscreen></iframe>

Similarly to the previous tasks, you should write a control function `solution4` that implements proportional regulators that controls the robot movement.

And analogically, we also prepared a simulation environment in CoppeliaSim stored in file `exercise02.ttt`.
You must open it in CoppeliaSim before running your matlab script.

Similarly, as in the previous tasks, the motion of the robot should be controlled by variables representing the relative velocities.

Additionally, you should gather and analyse data from the lidar sensors as described on page [Sensors]({{site.baseurl}}/03_references/06_sensors){:target="_blank"}.

{::comment}
 (the laser range sensors).
There are two variables that keep the LIDAR data:
* `pts` - a table containing LIDAR readings: the end-of-ray points, i.e. contact points of rays and obstacles in sensors's coordinates, each expressed as [x;y;z]
* `contacts` - a table of values (0 or 1) determining whether an obstactle was detected or the reading corresponds to the maximal sensor range (in this case it is set to 5m)

The input variables that describe the pose of the robot: `position` and `orientation` are not relevant in this tutorial.
The input data from the LIDAR sensor is sufficient to control the movements of the robot in a desired way.

To better understand the data acquired from LIDAR sensor, consider a simple example:
<div class="figure" style="width: 580px"><div><img style="border: 1px solid black; width: 560px" src="raster/lidar_small.jpg" alt="lidar_small" /></div></div>
In this example the LIRAR sends only three rays and one of them hits an obstacle. The array <code>pts</code> contains end-of-ray points
(the contact points of rays with obstacles), and in this particular case it is
<code class="block">-1.6  0.0   1.6<br>-1.6  -0.5   -1.6<br>0.08  0.08  0.08</code>
where each column represents x, y and z coordinates of the contact point of the laser ray and an obstacle.
If a laser ray is not hitting an obstacle, its contact point is at the end of the ray within a specified range (in the example, the LIDAR range is set to 2 m, so the rays end 2 meters from the sensor).
The <code>contacts</code> array contains values indicating if rays hit obstacles. In the example, the array is:
<code class="block">0 1 0</code>
The central ray hits an obstacle, so its corresponding value in the <code>contacts</code> array is 1. Also, its contact point in the <code>pts</code> table is [0, 0.5, 0.08].
As the other two rays are not in contact with obstacles, their corresponding values in the <code>contacts</code> array are 0 and their corresponding end-of-ray points in the
<code>pts</code> table are at distance of 2 m from the sensor (the maximal range of the sensor in this example).</p>

<p>Please note that the LIDAR sensor used in the simulator has range of 5 m and sends 684 rays, so the lengths of <code>pts</code> table and <code>contacts</code> array are 684.</p>
<div class="figure" style="width: 580px"><div><img style="border: 1px solid black; width: 560px" src="raster/lidar.jpg" alt="lidar_small" /></div></div>
{:/comment}

## Task requirements

* Analyse the lidar readings in order to find the nearest obstacle (please consider the XY plane readings only).
* The robot should keep given distance to the wall (e.g. 1 m), hence you must compute the relative errors in directions perpendicular and parallel to the wall.
* The resulting robot speed should be computed on the basis of those errors.
* Additionally, the robot must always face the wall, hence you must also adequtelly control the angular robot velocity.
* Do not use the input variables `position` and `orientation`, as they are not relevant.


## Grading
You can get 5 points, including:
* processing of the sensory data
* use of transformation frames
* regulator keeping distance from the wall
* regulator responsible for moving the robot along the wall
* regulator keeping the perpendicular orientation of the robot againts the wall
